# Batch Inference Implementation - Current Status & Next Steps

## âœ… **What's Working**

The enhanced inference system is **successfully implemented and tested**:

- **Caching**: 39% hit rate during self-play, LRU cache with configurable size
- **Batch Processing**: 3.8x speedup (1463 vs 385 boards/s)
- **Memory Management**: Stable usage, automatic batch size optimization
- **Performance Monitoring**: Real-time stats, throughput tracking
- **Self-Play Engine**: Successfully generating games with monitoring

## ðŸš¨ **Issues to Fix**

### 1. **Circular Import Issue**
**Problem**: `format_conversion.py` â†” `data_utils.py` circular dependency
**Impact**: Fragile imports, potential failures
**Solution**: Move `get_player_to_move_from_board` to separate utility module

### 2. **Code Duplication**
**Problem**: Board conversion logic duplicated between:
- `simple_model_inference.py` (`_create_board_with_correct_player_channel`)
- `format_conversion.py` (`board_nxn_to_3nxn`)
**Solution**: Use `board_nxn_to_3nxn()` consistently

### 3. **Deprecated Method Usage**
**Problem**: 9+ files still use `.infer()` instead of `.simple_infer()`
**Files affected**:
- `hex_ai/web/app.py` (3 instances)
- `hex_ai/inference/fixed_tree_search.py` (1 instance)
- `hex_ai/inference/game_engine.py` (1 instance)
- `hex_ai/value_utils.py` (2 instances)
- `hex_ai/inference/tournament.py` (1 instance)
- `scripts/simple_inference_cli.py` (1 instance)

## ðŸ”§ **Immediate Refactoring Tasks**

### **Phase 1: Fix Critical Issues (Priority 1)**

1. **Resolve Circular Import**
   Decide on the correct fix, e.g.
   ```python
   # Create: hex_ai/utils/player_utils.py
   def get_player_to_move_from_board(board_2ch: np.ndarray) -> Player:
       # Move from data_utils.py
   
   # Update imports in format_conversion.py and data_utils.py
   ```

2. **Consolidate Board Conversion**
   ```python
   # Remove _create_board_with_correct_player_channel from simple_model_inference.py
   # Use board_nxn_to_3nxn from format_conversion.py consistently
   ```

3. **Replace .infer() with .simple_infer()**
   ```python
   # Systematic replacement with proper error handling
   # Add deprecation warnings that guide users to new method
   ```

### **Phase 2: Clean Up Code Paths (Priority 2)**

1. **Standardize Policy Processing**
   - Use centralized utilities from `value_utils.py`
   - Remove duplicate logic in `simple_model_inference.py`

2. **Optimize Cache Management**
   - Dynamic cache sizing based on memory
   - Cache statistics and monitoring

3. **Improve Error Handling**
   - Better error messages for debugging
   - Graceful degradation for edge cases

## ðŸŽ¯ **End State Goals**

### **Clean Architecture**
- Single source of truth for board conversion
- No circular imports
- Consistent API across all inference code

### **Performance Optimization**
- Dynamic batch sizing based on hardware
- Intelligent cache management
- GPU memory optimization

### **Maintainability**
- Clear separation of concerns
- Comprehensive error handling
- Extensive test coverage

## ðŸš€ **Ready for Large-Scale Self-Play**

The system is **production-ready** for self-play generation:

```bash
# Generate 1000 games
python scripts/run_large_selfplay.py \
  --model-path "checkpoints/hyperparameter_tuning/loss_weight_sweep_exp0_bs256_98f719_20250724_233408/epoch2_mini16.pt.gz" \
  --num-games 1000 \
  --num-workers 4 \
  --batch-size 100
```

**Performance**: ~120 boards/s, 39% cache hit rate, stable memory usage

## ðŸ“‹ **Action Items**

### **Before Large-Scale Run**
- [ ] Fix circular import (30 min)
- [ ] Replace `.infer()` with `.simple_infer()` (1 hour)
- [ ] Consolidate board conversion (30 min)

### **After Large-Scale Run**
- [ ] Optimize cache management
- [ ] Add comprehensive error handling
- [ ] Improve performance monitoring
- [ ] Add integration tests

The system is **functional and ready** for immediate use, but these fixes will improve maintainability and reduce technical debt.